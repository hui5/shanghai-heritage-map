import { createOpenAI } from "@ai-sdk/openai";
import { Redis } from "@upstash/redis";
import { streamText } from "ai";

// Initialize Redis
const redis = new Redis({
  url: "https://bright-mammal-7064.upstash.io",
  token: "ARuYAAImcDEwODYzZWU1MTQzMzU0NTFjYTYyOGQ3OTliYmIxNDMyY3AxNzA2NA",
});
// Edge Runtimeé…ç½® - æ”¯æŒResponseå¯¹è±¡
export const config = {
  runtime: "edge",
};

interface GPTInfoRequest {
  name?: string;
  address?: string;
  coordinates?: [number, number];
  properties?: any;
}

interface CachedResponse {
  content: string;
  timestamp: number;
}

// é…ç½®è‡ªå®šä¹‰OpenAIæä¾›è€…
const openai = createOpenAI({
  apiKey: process.env.ZETA_API_KEY,
  baseURL: "https://api.zetatechs.com/v1",
});

// ç¼“å­˜é…ç½®
const CACHE_TTL = 24 * 60 * 60 * 30; // 30å¤© (ç§’)
const CACHE_PREFIX = "gpt_search:";

// ç”Ÿæˆç¼“å­˜é”®
async function generateCacheKey(requestData: GPTInfoRequest): Promise<string> {
  const normalized = {
    name: requestData.name?.trim().toLowerCase(),
    address: requestData.address?.trim().toLowerCase(),
    properties: requestData.properties,
  };

  const content = JSON.stringify(normalized, Object.keys(normalized).sort());

  // ä½¿ç”¨Web Crypto APIç”Ÿæˆå“ˆå¸Œ
  const encoder = new TextEncoder();
  const data = encoder.encode(content);
  const hashBuffer = await crypto.subtle.digest("SHA-256", data);
  const hashArray = Array.from(new Uint8Array(hashBuffer));
  const hash = hashArray
    .map((b) => b.toString(16).padStart(2, "0"))
    .join("")
    .slice(0, 16); // å–å‰16ä½

  return `${CACHE_PREFIX}${
    requestData.name
      ? requestData.name.replace(/[^a-zA-Z0-9]/g, "_")
      : "unknown"
  }_${hash}`;
}

// ä»ç¼“å­˜è·å–å“åº”
async function getCachedResponse(cacheKey: string): Promise<string | null> {
  try {
    const cached = await redis.get(cacheKey);
    if (!cached) return null;

    // å°è¯•è§£æç¼“å­˜æ•°æ®
    let parsedCache: CachedResponse;
    try {
      parsedCache =
        typeof cached === "string"
          ? JSON.parse(cached)
          : (cached as CachedResponse);
    } catch (parseError) {
      console.error("Cache parse error:", parseError);
      await redis.del(cacheKey); // åˆ é™¤æŸåçš„ç¼“å­˜
      return null;
    }

    // æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
    const now = Date.now();
    if (now - parsedCache.timestamp > CACHE_TTL * 1000) {
      await redis.del(cacheKey);
      return null;
    }

    return parsedCache.content;
  } catch (error) {
    console.error("Cache get error:", error);
    return null;
  }
}

// ç¼“å­˜å“åº”
async function setCachedResponse(
  cacheKey: string,
  content: string,
): Promise<void> {
  try {
    const cached: CachedResponse = {
      content,
      timestamp: Date.now(),
    };
    await redis.setex(cacheKey, CACHE_TTL, JSON.stringify(cached));
  } catch (error) {
    console.error("Cache set error:", error);
  }
}

export default async function handler(req: Request) {
  try {
    if (req.method !== "POST") {
      return new Response("Method not allowed", { status: 405 });
    }

    const body = await req.json();

    const { prompt, ...requestData }: { prompt: string } & GPTInfoRequest =
      body;

    console.log("ğŸ” gpt search: " + requestData.name);

    // ç”Ÿæˆç¼“å­˜é”®
    const cacheKey = await generateCacheKey(requestData);

    // æ£€æŸ¥ç¼“å­˜
    const cachedContent = await getCachedResponse(cacheKey);
    if (cachedContent) {
      console.log(
        "ğŸ“¦ Cache hit for:",
        requestData.name,
        "| Key:",
        cacheKey.slice(-8),
      );
      return new Response(cachedContent, {
        headers: {
          "Content-Type": "text/plain; charset=utf-8",
          "X-Cache": "HIT",
          "X-Cache-Key": cacheKey.slice(-8), // åªæ˜¾ç¤ºç¼“å­˜é”®çš„æœ€å8ä½ç”¨äºè°ƒè¯•
        },
      });
    }

    console.log("ğŸ”„ Cache miss, calling GPT for:", requestData.name);

    // æ„å»ºæŸ¥è¯¢ä¸Šä¸‹æ–‡
    const context = buildContextString(requestData);

    const result = streamText({
      model: openai("gpt-5-chat-latest"),
      system:
        "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ä¸Šæµ·å†å²æ–‡åŒ–ä¸“å®¶ï¼Œå¯¹ä¸Šæµ·çš„å»ºç­‘ã€å†å²ã€æ–‡åŒ–æœ‰æ·±å…¥äº†è§£ã€‚ç›®çš„æ˜¯ä»¥åœ°ç‚¹ä¸ºçº½å¸¦ï¼Œå…³è”å‡ºå»ºç­‘ï¼Œäººç‰©ï¼Œ æ—¶ä»£ ï¼Œäº‹ä»¶ï¼Œ æ•…äº‹ï¼Œ ä¸æ±‚é¢é¢ä¿±åˆ°ï¼Œä½†æ±‚æœ‰è¶£çš„çŸ¥è¯†ï¼Œç”ŸåŠ¨çš„ç»†èŠ‚ï¼Œä»¥å°è§å¤§çš„èƒ½åŠ›ã€‚ä½ çš„å›ç­”åº”è¯¥å‡†ç¡®ã€è¯¦ç»†ã€æœ‰è¶£,å°‘ç”¨å¥—è¯å’Œæ— æ„ä¹‰çš„è¯´æ•™ã€‚è¯·ä¸¥æ ¼æŒ‰ç…§ç”¨æˆ·è¦æ±‚çš„æ ¼å¼å›ç­”ï¼Œä½¿ç”¨markdownæ ¼å¼ã€‚",
      prompt: context,
      maxOutputTokens: 2000,
      temperature: 0.2,
    });

    // åˆ›å»ºä¸€ä¸ªå¯è¯»æµæ¥å¤„ç†æµå¼å“åº”å¹¶ç¼“å­˜å®Œæ•´å†…å®¹
    const stream = result.toUIMessageStreamResponse();

    // å¯¹äºæµå¼å“åº”ï¼Œæˆ‘ä»¬éœ€è¦æ”¶é›†å®Œæ•´å†…å®¹æ¥ç¼“å­˜
    return new Response(
      new ReadableStream({
        async start(controller) {
          const reader = stream.body?.getReader();
          if (!reader) {
            controller.close();
            return;
          }

          let fullContent = "";
          const decoder = new TextDecoder();

          try {
            while (true) {
              const { done, value } = await reader.read();

              if (done) {
                // æµç»“æŸï¼Œç¼“å­˜å®Œæ•´å†…å®¹
                if (fullContent.trim()) {
                  await setCachedResponse(cacheKey, fullContent);
                  console.log(
                    "ğŸ’¾ Cached response for:",
                    requestData.name,
                    "| Key:",
                    cacheKey.slice(-8),
                  );
                }
                controller.close();
                break;
              }

              const chunk = decoder.decode(value, { stream: true });
              fullContent += chunk;
              controller.enqueue(value);
            }
          } catch (error) {
            console.error("Stream processing error:", error);
            controller.error(error);
          }
        },
      }),
      {
        headers: {
          "Content-Type": "text/plain; charset=utf-8",
          "X-Cache": "MISS",
          "X-Cache-Key": cacheKey.slice(-8),
        },
      },
    );
  } catch (error) {
    console.error("API Error:", error);
    return new Response(
      JSON.stringify({
        error: "Internal server error",
        details: error instanceof Error ? error.message : "Unknown error",
      }),
      {
        status: 500,
        headers: {
          "Content-Type": "application/json",
        },
      },
    );
  }
}

function buildContextString({
  name,
  address,
  coordinates,
  properties,
}: GPTInfoRequest): string {
  let context = "è¯·ä¸ºä»¥ä¸‹ä¸Šæµ·çš„åœ°ç‚¹æä¾›è¯¦ç»†çš„å†å²æ–‡åŒ–ä¿¡æ¯ï¼š\n\n";

  if (name) {
    context += `åç§°: ${name}\n`;
  }

  if (address) {
    context += `åœ°å€: ${address}\n`;
  }

  if (properties) {
    context += `å…¶å®ƒ: ${JSON.stringify(properties)}`;
  }

  context += `

ä»¥ä¸Šé¢æä¾›çš„ä¿¡æ¯ä¸ºåŸºç¡€ï¼Œç»“åˆä¸Šæµ·çš„å†å²æ–‡åŒ–èƒŒæ™¯ï¼Œç”¨markdownæ ¼å¼æä¾›æ›´è¯¦ç»†çš„å»ºç­‘å†å²ä»‹ç»ã€‚

è¦æ±‚ï¼š
1. ä½¿ç”¨ä¸­æ–‡å›ç­”
2. å……åˆ†åˆ©ç”¨æä¾›çš„æ‰€æœ‰æ•°æ®ä¿¡æ¯ï¼ŒåŒæ—¶æŸ¥è¯¢å¯èƒ½çš„ç›¸å…³èµ„æ–™
3. ä»¥çŸ¥è¯†ä»‹ç»ä¸ºä¸»ï¼Œä¸è¦è®²æ„ä¹‰ï¼Œæ–‡å­—è¦ç²¾ç‚¼
4. ç»™å‡ºå†å²æ²¿é©ï¼Œç›¸å…³äººç‰©äº‹ä»¶
5. å†…å®¹è¦ä¸°å¯Œå…·ä½“ï¼Œç»“æ„æ¸…æ™°
6. ä½¿ç”¨markdownè¯­æ³•ï¼ŒåŒ…æ‹¬æ ‡é¢˜ã€æ®µè½ã€åˆ—è¡¨ç­‰æ ¼å¼
7. å¦‚æœæŸäº›ä¿¡æ¯ä¸ç¡®å®šæˆ–èµ„æ–™ä¸è¶³ï¼Œä¸è¦æ¨æµ‹
8. å¯¹å»ºç­‘æœ¬èº«çš„ä»‹ç»è¦ç®€æ´ï¼Œ ä¾§é‡äºå»ºç­‘ç›¸å…³çš„äººå’Œäº‹
9. é¿å…è¾“å‡ºå›¾ç‰‡åœ°å€
10.ç»“å°¾é¿å…ç»™å‡ºä»»ä½•å»ºè®®ã€è¯¢é—®
`;

  return context;
}
